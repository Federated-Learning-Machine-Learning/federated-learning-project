{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXzQZhEOm54h",
        "outputId": "bf08c3b5-9ea8-44ec-b150-e328017f245e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flwr[simulation] in /usr/local/lib/python3.11/dist-packages (1.18.0)\n",
            "Requirement already satisfied: cryptography<45.0.0,>=44.0.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (44.0.3)\n",
            "Requirement already satisfied: grpcio!=1.65.0,<2.0.0,>=1.62.3 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.71.0)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.0.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.0.2)\n",
            "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.12.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.21.6 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (4.25.8)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (3.23.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (6.0.2)\n",
            "Requirement already satisfied: ray==2.31.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.31.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (13.9.4)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.2.1)\n",
            "Requirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.2.0)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.12.5)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (8.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (24.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<45.0.0,>=44.0.1->flwr[simulation]) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (2.19.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (4.13.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<45.0.0,>=44.0.1->flwr[simulation]) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr[simulation]) (0.1.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (0.25.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.31.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr torch torchvision tensorboard\n",
        "!pip install -U \"flwr[simulation]\"\n",
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5Xp1pUuaE6mR"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from functools import partial\n",
        "from flwr.server import ServerConfig\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "import torch\n",
        "import os\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import flwr as fl\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr.common import Context\n",
        "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
        "from flwr.client import ClientApp\n",
        "from flwr.common import parameters_to_ndarrays, ndarrays_to_parameters\n",
        "from flwr.common import Parameters\n",
        "from collections import OrderedDict\n",
        "from wandb_logger import FederatedWandBLogger\n",
        "import data_utils\n",
        "import clients\n",
        "import strategies\n",
        "import data_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HOv-t1R19VaF"
      },
      "outputs": [],
      "source": [
        "def build_optimizer_config(optimizer_type):\n",
        "    if optimizer_type == clients.OptimizerType.SGD:\n",
        "        config = {\n",
        "            \"lr\": LR,\n",
        "            \"momentum\": MOMENTUM,\n",
        "            \"weight_decay\": WEIGHT_DECAY,\n",
        "            \"nesterov\": NESTEROV\n",
        "        }\n",
        "\n",
        "    elif optimizer_type == clients.OptimizerType.SSGD:\n",
        "        config = {\n",
        "            \"lr\": LR,\n",
        "            \"momentum\": MOMENTUM,\n",
        "            \"weight_decay\": WEIGHT_DECAY,\n",
        "        }\n",
        "\n",
        "\n",
        "    elif optimizer_type == clients.OptimizerType.ADAM:\n",
        "        config = {\n",
        "            \"lr\": LR,\n",
        "            \"betas\": BETAS,\n",
        "            \"weight_decay\": WEIGHT_DECAY,\n",
        "            \"eps\": EPSILON\n",
        "        }\n",
        "\n",
        "    elif optimizer_type == clients.OptimizerType.ADAMW:\n",
        "        config = {\n",
        "            \"lr\": LR,\n",
        "            \"betas\": BETAS,\n",
        "            \"weight_decay\": WEIGHT_DECAY\n",
        "        }\n",
        "\n",
        "    elif optimizer_type == clients.OptimizerType.SADAMW:\n",
        "        config = {\n",
        "            \"lr\": LR,\n",
        "            \"betas\": BETAS,\n",
        "            \"weight_decay\": WEIGHT_DECAY,\n",
        "            \"eps\": EPSILON\n",
        "        }\n",
        "\n",
        "    elif optimizer_type == clients.OptimizerType.RMSPROP:\n",
        "        config = {\n",
        "            \"lr\": LR,\n",
        "            \"alpha\": ALPHA,\n",
        "            \"eps\": EPSILON,\n",
        "            \"weight_decay\": WEIGHT_DECAY,\n",
        "            \"momentum\": MOMENTUM,\n",
        "            \"centered\": CENTERED\n",
        "        }\n",
        "\n",
        "    elif optimizer_type == clients.OptimizerType.ADAGRAD:\n",
        "        config = {\n",
        "            \"lr\": LR,\n",
        "            \"weight_decay\": WEIGHT_DECAY,\n",
        "            \"eps\": EPSILON\n",
        "        }\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported optimizer type: {optimizer_type}\")\n",
        "\n",
        "    print(f\"Optimizer '{optimizer_type}' initialized successfully.\")\n",
        "    return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "On2yMJDV9L6v"
      },
      "outputs": [],
      "source": [
        "def build_scheduler_config(scheduler_type):\n",
        "    scheduler_type.lower()\n",
        "\n",
        "    if scheduler_type == \"cosine\":\n",
        "        config = {\n",
        "            \"T_max\": T_MAX,\n",
        "            \"eta_min\": ETA_MIN\n",
        "        }\n",
        "\n",
        "    elif scheduler_type == \"cosine_restart\":\n",
        "        config = {\n",
        "            \"T_0\": T_MAX,\n",
        "            \"T_mult\": 1,\n",
        "            \"eta_min\": ETA_MIN\n",
        "        }\n",
        "\n",
        "    elif scheduler_type == \"step\":\n",
        "        config = {\n",
        "            \"step_size\": STEP_SIZE,\n",
        "            \"gamma\": GAMMA\n",
        "        }\n",
        "\n",
        "    elif scheduler_type == \"multistep\":\n",
        "        config = {\n",
        "            \"milestones\": MILESTONES,\n",
        "            \"gamma\": GAMMA\n",
        "        }\n",
        "\n",
        "    elif scheduler_type == \"exponential\":\n",
        "        config = {\n",
        "            \"gamma\": GAMMA\n",
        "        }\n",
        "\n",
        "    elif scheduler_type == \"reduce_on_plateau\":\n",
        "        config = {\n",
        "            \"mode\": \"min\",\n",
        "            \"factor\": FACTOR,\n",
        "            \"patience\": PATIENCE,\n",
        "            \"threshold\": THRESHOLD\n",
        "        }\n",
        "\n",
        "    elif scheduler_type == \"constant\":\n",
        "        config = {\n",
        "            \"factor\": 1.0,\n",
        "            \"total_iters\": TOTAL_ITERS\n",
        "        }\n",
        "\n",
        "    elif scheduler_type == \"linear\":\n",
        "        config = {\n",
        "            \"start_factor\": 0.5,\n",
        "            \"end_factor\": LR_END,\n",
        "            \"total_iters\": TOTAL_ITERS\n",
        "        }\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported scheduler type: {scheduler_type}\")\n",
        "\n",
        "    print(f\"Scheduler '{scheduler_type}' initialized successfully.\")\n",
        "    return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qbmrMF8AzgV6"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1799ScT_ohcp",
        "outputId": "45c082a5-32af-4d77-9778-be81e3a4ba2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizer 'OptimizerType.SADAMW' initialized successfully.\n",
            "Scheduler 'cosine' initialized successfully.\n"
          ]
        }
      ],
      "source": [
        "# THE WHOLE TRAINING SETTINGS ARE HERE!\n",
        "\n",
        "# GENERAL\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 15\n",
        "VAL_SPLIT = 0.1\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BACKBONE_FREEZING = False\n",
        "\n",
        "# FL\n",
        "NUM_CLIENTS = 10\n",
        "NC = 50\n",
        "LOCAL_EPOCHS = 1\n",
        "NUM_ROUNDS = 25\n",
        "FRACTION_FIT = 0.1\n",
        "FRACTION_EVAL = 0.03\n",
        "CLIENT_TYPE = clients.ClientType.TALOSPFEDEDIT\n",
        "STRATEGY_TYPE = strategies.StrategiesType.YOGI\n",
        "IID = False\n",
        "\n",
        "# LOSS\n",
        "SMOOTHING=0.1\n",
        "\n",
        "# Optimizer Hyperparameters\n",
        "LR = 0.00005\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0.025\n",
        "NESTEROV = False\n",
        "BETAS = (0.9, 0.999)\n",
        "EPSILON = 1e-8\n",
        "ALPHA = 0.99\n",
        "CENTERED = False\n",
        "OPTIMIZER_TYPE  = clients.OptimizerType.SADAMW\n",
        "\n",
        "# Scheduler Hyperparameters\n",
        "T_MAX = LOCAL_EPOCHS\n",
        "ETA_MIN = 0.0\n",
        "STEP_SIZE = 30\n",
        "GAMMA = 0.1\n",
        "MILESTONES = [50, 75]\n",
        "FACTOR = 0.1\n",
        "PATIENCE = 5\n",
        "THRESHOLD = 1e-4\n",
        "TOTAL_ITERS = 10\n",
        "LR_END = 0.0\n",
        "SCHEDULER_TYPE  = \"cosine\"\n",
        "\n",
        "TALOS_CONFIG = {\n",
        "    \"final_sparsity\": 0.6,\n",
        "    \"num_batches\": 3,\n",
        "    \"rounds\": 4,\n",
        "    \"calibration_mode\": \"most_sensitive\", # least_sensitive or most_sensitive\n",
        "    \"mode\": \"full\", # full if want to include all layers, head for head only, pfededit for custom topk client selection\n",
        "    \"k\": 3, #pfedit setting\n",
        "}\n",
        "\n",
        "# FedProx\n",
        "\n",
        "MU = 0.1\n",
        "\n",
        "# YOGI\n",
        "\n",
        "ETA = 0.5         # Learning rate for Yogi updates\n",
        "ETA_L = 0.25      # Learning rate for local updates\n",
        "TAU = 0.1            # Adaptive learning parameter for Yogi\n",
        "BETA_1 = 0.9         # Momentum term (default value from the original paper)\n",
        "BETA_2 = 0.999       # Second momentum term (default value from the original paper)\n",
        "\n",
        "# METAFEDAVG\n",
        "\n",
        "INNER_LR = 0.01\n",
        "\n",
        "#PFEDEDIT\n",
        "LOCAL_EPOCHS_PFEDEDIT = 4\n",
        "TOP_K_LAYERS = 3\n",
        "#STOCHASTIC_FACTOR = 1\n",
        "MAX_BATCHES = 4\n",
        "DETERMINISTIC_ROUND = 10\n",
        "ALL_ROUNDS_SCHEDULING = True\n",
        "REVERSE_MODE = False\n",
        "PFEDEDIT_CONFIG = {\n",
        "    \"local epochs\": LOCAL_EPOCHS_PFEDEDIT,\n",
        "    \"top_k_layers\": TOP_K_LAYERS,\n",
        "    \"stochastic factor\": \"linear decrease\",\n",
        "    \"max_batches\": MAX_BATCHES,\n",
        "    \"deterministic_round\": DETERMINISTIC_ROUND,\n",
        "    \"all_rounds_scheduling\": ALL_ROUNDS_SCHEDULING,\n",
        "    \"reverse_mode\": REVERSE_MODE,\n",
        "}\n",
        "\n",
        "\n",
        "OPTIMIZER_CONFIG = build_optimizer_config(OPTIMIZER_TYPE)\n",
        "SCHEDULER_CONFIG = build_scheduler_config(SCHEDULER_TYPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO_pxQucjrtp",
        "outputId": "0e8c2772-471a-4dbb-a915-c9b2e067066d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete. IID and Non-IID splits created.\n"
          ]
        }
      ],
      "source": [
        "pipeline = data_preprocessing.CIFAR100Pipeline(val_split=VAL_SPLIT, use_augment=True)\n",
        "trainset, valset, testset = pipeline.run_pipeline()\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valloader = DataLoader(valset, batch_size=BATCH_SIZE)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Apply sharding\n",
        "client_datasets_iid = data_utils.iid_split(trainset, NUM_CLIENTS)\n",
        "client_datasets_noniid = data_utils.non_iid_split(trainset, NUM_CLIENTS, NC, 100)\n",
        "\n",
        "print(\"Setup complete. IID and Non-IID splits created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1Q4llQU021yr"
      },
      "outputs": [],
      "source": [
        "# Create model\n",
        "def create_dino_vit_s16_for_cifar100(freezing=BACKBONE_FREEZING):\n",
        "    model = timm.create_model(\"vit_small_patch16_224_dino\", pretrained=True, num_classes=0)\n",
        "\n",
        "    # Replace the head with CIFAR-100 classification head\n",
        "    model.head = nn.Linear(model.num_features, 100)\n",
        "\n",
        "    if freezing:\n",
        "      # Freeze all parameters except head\n",
        "      for param in model.parameters():\n",
        "          param.requires_grad = False\n",
        "\n",
        "      # Unfreeze only the head\n",
        "      for param in model.head.parameters():\n",
        "          param.requires_grad = True\n",
        "    else:\n",
        "\n",
        "      for param in model.parameters():\n",
        "          param.requires_grad = True\n",
        "\n",
        "      for param in model.head.parameters():\n",
        "          param.requires_grad = True\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9cDNl8r2qQv",
        "outputId": "c48a07c5-f30b-4ac3-b95b-08247a5eed84"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name vit_small_patch16_224_dino to current vit_small_patch16_224.dino.\n",
            "  model = create_fn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Trainable params: 21,704,164 / 21,704,164\n"
          ]
        }
      ],
      "source": [
        "model = create_dino_vit_s16_for_cifar100()\n",
        "\n",
        "print(next(model.parameters()).device)\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Trainable params: {trainable:,} / {total:,}\")\n",
        "\n",
        "initial_parameters = [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
        "flower_parameters = ndarrays_to_parameters(initial_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_sfWIx8_SRu",
        "outputId": "6bf85bd1-d306-4a55-94d6-dc379e65fe78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using legacy-service, which is deprecated. If this is unintentional, you can fix it by ensuring you do not call `wandb.require('legacy-service')` and do not set the WANDB_X_REQUIRE_LEGACY_SERVICE environment variable.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!wandb login 89e5fee022a3a1cf86f958ee0b3dff6f2aa57aad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "31KOm819XUko",
        "outputId": "727200a1-a996-49f2-d61d-18b930b26b2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  return LooseVersion(v) >= LooseVersion(check)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms348517giuseppe\u001b[0m (\u001b[33ms348517giuseppe-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "/usr/local/lib/python3.11/dist-packages/wandb/analytics/sentry.py:259: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
            "  self.scope.user = {\"email\": email}  # noqa\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250602_150434-8qmtczmf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/polito-fl/federated-learning-project/runs/8qmtczmf' target=\"_blank\">FEDERATED_NON_IID_DATA_TALOS_20250602-150433</a></strong> to <a href='https://wandb.ai/polito-fl/federated-learning-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/polito-fl/federated-learning-project' target=\"_blank\">https://wandb.ai/polito-fl/federated-learning-project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/polito-fl/federated-learning-project/runs/8qmtczmf' target=\"_blank\">https://wandb.ai/polito-fl/federated-learning-project/runs/8qmtczmf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_distribution = \"IID_DATA\" if IID else \"NON_IID_DATA\"\n",
        "run_name = f\"FEDERATED_{data_distribution}_TALOS_{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "\n",
        "if CLIENT_TYPE == clients.ClientType.TALOS:\n",
        "    client_app = ClientApp(\n",
        "        client_fn=clients.build_client_talos_fn(\n",
        "            use_iid=IID,\n",
        "            optimizer_type=OPTIMIZER_TYPE,\n",
        "            optimizer_config=OPTIMIZER_CONFIG,\n",
        "            scheduler_type=SCHEDULER_TYPE,\n",
        "            scheduler_config=SCHEDULER_CONFIG,\n",
        "            iid_partitions=client_datasets_iid,\n",
        "            non_iid_partitions=client_datasets_noniid,\n",
        "            model_fn=create_dino_vit_s16_for_cifar100,\n",
        "            device=DEVICE,\n",
        "            valset=valset,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            local_epochs=LOCAL_EPOCHS,\n",
        "            talos_config=TALOS_CONFIG,\n",
        "\n",
        "        )\n",
        "    )\n",
        "    client_config = None\n",
        "elif CLIENT_TYPE == clients.ClientType.TALOSPROX:\n",
        "    client_app = ClientApp(\n",
        "        client_fn=clients.build_client_talos_prox_fn(\n",
        "            use_iid=IID,\n",
        "            optimizer_type=OPTIMIZER_TYPE,\n",
        "            optimizer_config=OPTIMIZER_CONFIG,\n",
        "            scheduler_type=SCHEDULER_TYPE,\n",
        "            scheduler_config=SCHEDULER_CONFIG,\n",
        "            iid_partitions=client_datasets_iid,\n",
        "            non_iid_partitions=client_datasets_noniid,\n",
        "            model_fn=create_dino_vit_s16_for_cifar100,\n",
        "            device=DEVICE,\n",
        "            valset=valset,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            local_epochs=LOCAL_EPOCHS,\n",
        "            talos_config=TALOS_CONFIG,\n",
        "            mu=MU\n",
        "        )\n",
        "    )\n",
        "    client_config = {\"mu\": MU}\n",
        "\n",
        "elif CLIENT_TYPE == clients.ClientType.TALOSPFEDEDIT:\n",
        "    client_app = ClientApp(\n",
        "        client_fn=clients.build_client_fn_talos_pfededit(\n",
        "            use_iid=IID,\n",
        "            optimizer_type=OPTIMIZER_TYPE,\n",
        "            optimizer_config=OPTIMIZER_CONFIG,\n",
        "            scheduler_type=SCHEDULER_TYPE,\n",
        "            scheduler_config=SCHEDULER_CONFIG,\n",
        "            iid_partitions=client_datasets_iid,\n",
        "            non_iid_partitions=client_datasets_noniid,\n",
        "            model_fn=create_dino_vit_s16_for_cifar100,\n",
        "            device=DEVICE,\n",
        "            valset=valset,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            local_epochs=LOCAL_EPOCHS,\n",
        "            talos_config=TALOS_CONFIG,\n",
        "            pfededit_config = PFEDEDIT_CONFIG,\n",
        "            rounds_stochastic = NUM_ROUNDS,\n",
        "            deterministic_round = DETERMINISTIC_ROUND,\n",
        "            all_rounds_scheduling = ALL_ROUNDS_SCHEDULING,\n",
        "            reverse_mode = REVERSE_MODE\n",
        "\n",
        "        )\n",
        "    )\n",
        "    client_config = {\"mu\": MU}\n",
        "\n",
        "if STRATEGY_TYPE == strategies.StrategiesType.FEDAVG:\n",
        "    strategy_config = None\n",
        "elif STRATEGY_TYPE == strategies.StrategiesType.METAFEDAVG:\n",
        "    strategy_config = {\"inner_lr\": INNER_LR}\n",
        "else:\n",
        "    strategy_config = {\"eta\": ETA, \"eta_l\": ETA_L, \"tau\": TAU, \"beta_1\": BETA_1, \"beta_2\": BETA_2,}\n",
        "\n",
        "\n",
        "if not IID:\n",
        "  DataConfig = {\"use_iid\": IID, \"num_classes\": NC}\n",
        "else:\n",
        "  DataConfig = {\"use_iid\": IID}\n",
        "\n",
        "\n",
        "logger = FederatedWandBLogger(\n",
        "    project_name=\"federated-learning-project\",\n",
        "    run_name=run_name,\n",
        "    global_config={\n",
        "        # Federated Learning Configuration\n",
        "        \"data_config\": DataConfig,\n",
        "        \"local_epochs\": LOCAL_EPOCHS,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"num_clients\": NUM_CLIENTS,\n",
        "        \"fraction_fit\": FRACTION_FIT,\n",
        "        \"fraction_evaluate\": FRACTION_EVAL,\n",
        "        \"num_rounds\": NUM_ROUNDS,\n",
        "        \"backbone_freezing\": BACKBONE_FREEZING,\n",
        "        \"client_type\": CLIENT_TYPE.value,\n",
        "        \"client_config\": client_config,\n",
        "        \"strategy_type\": STRATEGY_TYPE.value,\n",
        "        \"strategy_config\": strategy_config,\n",
        "        \"val_split\": VAL_SPLIT,\n",
        "\n",
        "        # Optimizer Configuration\n",
        "        \"optimizer\": OPTIMIZER_TYPE.value,\n",
        "        \"optimizer_config\": OPTIMIZER_CONFIG,\n",
        "\n",
        "        # Scheduler Configuration\n",
        "        \"scheduler\": SCHEDULER_TYPE,\n",
        "        \"scheduler_config\": SCHEDULER_CONFIG,\n",
        "\n",
        "        \"talos_config\": TALOS_CONFIG,\n",
        "\n",
        "        \"pfededit_config\": PFEDEDIT_CONFIG\n",
        "\n",
        "\n",
        "    }\n",
        ")\n",
        "\n",
        "if STRATEGY_TYPE == strategies.StrategiesType.FEDAVG:\n",
        "    strategy = strategies.FedAvgStandard(\n",
        "        logger=logger,\n",
        "        initial_parameters=flower_parameters,\n",
        "        fraction_fit=FRACTION_FIT,\n",
        "        min_fit_clients=int(FRACTION_FIT*NUM_CLIENTS),\n",
        "        min_evaluate_clients=int(FRACTION_EVAL*NUM_CLIENTS),\n",
        "        fraction_evaluate=FRACTION_EVAL,\n",
        "        min_available_clients=NUM_CLIENTS,\n",
        "        evaluate_metrics_aggregation_fn = lambda metrics: {\n",
        "            \"accuracy\": sum(num * m[\"val_accuracy\"] for num, m in metrics) / sum(num for num, _ in metrics)\n",
        "        }\n",
        "    )\n",
        "elif STRATEGY_TYPE == strategies.StrategiesType.METAFEDAVG:\n",
        "    strategy = strategies.MetaFedAvg(\n",
        "        logger=logger,\n",
        "        inner_lr=INNER_LR,\n",
        "        initial_parameters=flower_parameters,\n",
        "        fraction_fit=FRACTION_FIT,\n",
        "        min_fit_clients=int(FRACTION_FIT*NUM_CLIENTS),\n",
        "        min_evaluate_clients=int(FRACTION_EVAL*NUM_CLIENTS),\n",
        "        fraction_evaluate=FRACTION_EVAL,\n",
        "        min_available_clients=NUM_CLIENTS,\n",
        "        evaluate_metrics_aggregation_fn = lambda metrics: {\n",
        "            \"accuracy\": sum(num * m[\"val_accuracy\"] for num, m in metrics) / sum(num for num, _ in metrics)\n",
        "        }\n",
        "    )\n",
        "else:\n",
        "    strategy = strategies.FedYogiStandard(\n",
        "        logger=logger,\n",
        "        initial_parameters=flower_parameters,\n",
        "        fraction_fit=FRACTION_FIT,\n",
        "        min_fit_clients=int(FRACTION_FIT*NUM_CLIENTS),\n",
        "        min_evaluate_clients=int(FRACTION_EVAL*NUM_CLIENTS),\n",
        "        fraction_evaluate=FRACTION_EVAL,\n",
        "        min_available_clients=NUM_CLIENTS,\n",
        "        eta=ETA,\n",
        "        eta_l=ETA_L,\n",
        "        tau=TAU,\n",
        "        beta_1=BETA_1,\n",
        "        beta_2=BETA_2,\n",
        "        evaluate_metrics_aggregation_fn = lambda metrics: {\n",
        "            \"accuracy\": sum(num * m[\"val_accuracy\"] for num, m in metrics) / sum(num for num, _ in metrics)\n",
        "        }\n",
        "    )\n",
        "\n",
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    \"\"\"Construct components that set the ServerApp behaviour.\n",
        "\n",
        "    You can use the settings in `context.run_config` to parameterize the\n",
        "    construction of all elements (e.g the strategy or the number of rounds)\n",
        "    wrapped in the returned ServerAppComponents object.\n",
        "    \"\"\"\n",
        "    config = ServerConfig(num_rounds=NUM_ROUNDS)\n",
        "    return ServerAppComponents(strategy=strategy, config=config)\n",
        "\n",
        "\n",
        "server_app = ServerApp(server_fn=server_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9To1c6PtSman"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VmOdfanrsuOM",
        "outputId": "9e75da53-e2e7-48d9-b3a0-3eb4ba93b923"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:flwr:Asyncio event loop already running.\n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=25, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 1 clients (out of 10)\n",
            "\u001b[36m(pid=10078)\u001b[0m 2025-06-02 15:04:45.103512: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=10078)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=10078)\u001b[0m E0000 00:00:1748876685.135903   10078 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=10078)\u001b[0m E0000 00:00:1748876685.145920   10078 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m /usr/local/lib/python3.11/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name vit_small_patch16_224_dino to current vit_small_patch16_224.dino.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m   model = create_fn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m LOG: Initializing client with CID=3\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Data partition assigned to client 3 -> Non-IID\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Model initialized for client 3\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Dataloaders initialized for client 3\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Initialized with FedProx Œº = 0.1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Current Round: 1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Total Rounds: 10\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Using normal mode for scheduling\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Round 1 | Dynamic Stochastic Factor: 1.0000\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Random Sample: 0.8276\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Stochastic Sampling Activated (stochastic_factor=1.0000), Full Model Training\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üü¢ Pruning will be applied to the entire model.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Starting TaLoS calibration in mode: full\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîé Starting multi-round calibration for mode 'full'.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 1/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 2/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 3/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 4/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mask Calibration Completed!\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîç Mapping parameters to their masks...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mapped 150 parameters to masks.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Using SparseAdamW optimizer\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Starting epoch 1/1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Completed local training - Loss: 5.3508 | Accuracy: 0.0850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 1 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregating fit results for round 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m LOG: Initializing client with CID=3\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Data partition assigned to client 3 -> Non-IID\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Model initialized for client 3\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Dataloaders initialized for client 3\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Initialized with FedProx Œº = 0.1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Current Round: 2\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Total Rounds: 10\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Using normal mode for scheduling\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Round 2 | Dynamic Stochastic Factor: 0.8889\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Random Sample: 0.0765\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Stochastic Sampling Activated (stochastic_factor=0.8889), Full Model Training\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üü¢ Pruning will be applied to the entire model.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Starting TaLoS calibration in mode: full\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîé Starting multi-round calibration for mode 'full'.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 1/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 2/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 3/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 4/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mask Calibration Completed!\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîç Mapping parameters to their masks...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mapped 150 parameters to masks.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Using SparseAdamW optimizer\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Starting epoch 1/1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Completed local training - Loss: 4.9674 | Accuracy: 0.0870\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 1 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregating fit results for round 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m LOG: Initializing client with CID=6\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Data partition assigned to client 6 -> Non-IID\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Model initialized for client 6\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Dataloaders initialized for client 6\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Initialized with FedProx Œº = 0.1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Current Round: 3\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Total Rounds: 10\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Using normal mode for scheduling\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Round 3 | Dynamic Stochastic Factor: 0.7778\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Random Sample: 0.5250\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Stochastic Sampling Activated (stochastic_factor=0.7778), Full Model Training\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üü¢ Pruning will be applied to the entire model.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Starting TaLoS calibration in mode: full\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîé Starting multi-round calibration for mode 'full'.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 1/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 2/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 3/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 4/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mask Calibration Completed!\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîç Mapping parameters to their masks...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mapped 150 parameters to masks.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Using SparseAdamW optimizer\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Starting epoch 1/1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Completed local training - Loss: 5.4804 | Accuracy: 0.0378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 1 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregating fit results for round 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m LOG: Initializing client with CID=5\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Data partition assigned to client 5 -> Non-IID\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Model initialized for client 5\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Dataloaders initialized for client 5\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Initialized with FedProx Œº = 0.1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Current Round: 4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Total Rounds: 10\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Using normal mode for scheduling\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Round 4 | Dynamic Stochastic Factor: 0.6667\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Random Sample: 0.5005\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Stochastic Sampling Activated (stochastic_factor=0.6667), Full Model Training\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üü¢ Pruning will be applied to the entire model.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Starting TaLoS calibration in mode: full\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîé Starting multi-round calibration for mode 'full'.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 1/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 2/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 3/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 4/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mask Calibration Completed!\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîç Mapping parameters to their masks...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mapped 150 parameters to masks.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Using SparseAdamW optimizer\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Starting epoch 1/1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Completed local training - Loss: 4.7236 | Accuracy: 0.0694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 1 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregating fit results for round 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m LOG: Initializing client with CID=6\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Data partition assigned to client 6 -> Non-IID\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Model initialized for client 6\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Dataloaders initialized for client 6\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Initialized with FedProx Œº = 0.1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Current Round: 5\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Total Rounds: 10\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Using normal mode for scheduling\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Round 5 | Dynamic Stochastic Factor: 0.5556\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Random Sample: 0.8655\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: TaLoS Local Layer Selection (stochastic_factor=0.5556)\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Max Batches: 4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Selected Layers (Min Loss): [7, 4, 1]\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üü¢ Pruning will be applied to the following layers: [7, 4, 1]\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Starting TaLoS calibration in mode: pfededit\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîé Starting multi-round calibration for mode 'pfededit'.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 1/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 2/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 3/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 4/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mask Calibration Completed!\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîç Mapping parameters to their masks...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mapped 36 parameters to masks.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Using SparseAdamW optimizer\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Starting epoch 1/1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 6-LOG: Completed local training - Loss: 4.2177 | Accuracy: 0.0578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 1 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregating fit results for round 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m LOG: Initializing client with CID=4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Data partition assigned to client 4 -> Non-IID\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Model initialized for client 4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Dataloaders initialized for client 4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Initialized with FedProx Œº = 0.1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Current Round: 6\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Total Rounds: 10\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Using normal mode for scheduling\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Round 6 | Dynamic Stochastic Factor: 0.4444\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Random Sample: 0.5250\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: TaLoS Local Layer Selection (stochastic_factor=0.4444)\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Max Batches: 4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Selected Layers (Min Loss): [6, 1, 0]\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üü¢ Pruning will be applied to the following layers: [6, 1, 0]\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Starting TaLoS calibration in mode: pfededit\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîé Starting multi-round calibration for mode 'pfededit'.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 1/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 2/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 3/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 4/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mask Calibration Completed!\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîç Mapping parameters to their masks...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mapped 36 parameters to masks.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Using SparseAdamW optimizer\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Starting epoch 1/1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Completed local training - Loss: 4.8517 | Accuracy: 0.0218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 1 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregating fit results for round 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m LOG: Initializing client with CID=3\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Data partition assigned to client 3 -> Non-IID\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Model initialized for client 3\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Dataloaders initialized for client 3\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Initialized with FedProx Œº = 0.1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Current Round: 7\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Total Rounds: 10\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Using normal mode for scheduling\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Round 7 | Dynamic Stochastic Factor: 0.3333\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Random Sample: 0.0125\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Stochastic Sampling Activated (stochastic_factor=0.3333), Full Model Training\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üü¢ Pruning will be applied to the entire model.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Starting TaLoS calibration in mode: full\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîé Starting multi-round calibration for mode 'full'.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 1/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 2/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 3/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 4/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mask Calibration Completed!\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîç Mapping parameters to their masks...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mapped 150 parameters to masks.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Using SparseAdamW optimizer\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Starting epoch 1/1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Completed local training - Loss: 4.0941 | Accuracy: 0.0850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 1 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregating fit results for round 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m LOG: Initializing client with CID=5\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Data partition assigned to client 5 -> Non-IID\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Model initialized for client 5\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Dataloaders initialized for client 5\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Initialized with FedProx Œº = 0.1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Current Round: 8\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Total Rounds: 10\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Using normal mode for scheduling\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Round 8 | Dynamic Stochastic Factor: 0.2222\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Random Sample: 0.7331\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: TaLoS Local Layer Selection (stochastic_factor=0.2222)\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Max Batches: 4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Selected Layers (Min Loss): [10, 0, 6]\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üü¢ Pruning will be applied to the following layers: [10, 0, 6]\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Starting TaLoS calibration in mode: pfededit\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîé Starting multi-round calibration for mode 'pfededit'.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 1/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 2/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 3/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 4/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mask Calibration Completed!\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîç Mapping parameters to their masks...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mapped 36 parameters to masks.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Using SparseAdamW optimizer\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Starting epoch 1/1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 5-LOG: Completed local training - Loss: 3.8074 | Accuracy: 0.0694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 1 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregating fit results for round 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m LOG: Initializing client with CID=8\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 8-LOG: Data partition assigned to client 8 -> Non-IID\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 8-LOG: Model initialized for client 8\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 8-LOG: Dataloaders initialized for client 8\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 8-LOG: Initialized with FedProx Œº = 0.1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Current Round: 9\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Total Rounds: 10\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 8-LOG: Using normal mode for scheduling\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 8-LOG: Round 9 | Dynamic Stochastic Factor: 0.1111\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 8-LOG: Random Sample: 0.5138\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 8-LOG: TaLoS Local Layer Selection (stochastic_factor=0.1111)\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Max Batches: 4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 8-LOG: Selected Layers (Min Loss): [6, 7, 1]\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üü¢ Pruning will be applied to the following layers: [6, 7, 1]\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 8-LOG: Starting TaLoS calibration in mode: pfededit\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîé Starting multi-round calibration for mode 'pfededit'.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 1/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 2/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 3/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 4/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mask Calibration Completed!\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîç Mapping parameters to their masks...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mapped 36 parameters to masks.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 8-LOG: Using SparseAdamW optimizer\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 8-LOG: Starting epoch 1/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 1 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 8-LOG: Completed local training - Loss: 4.8195 | Accuracy: 0.0437\n",
            "Aggregating fit results for round 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m LOG: Initializing client with CID=4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Data partition assigned to client 4 -> Non-IID\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Model initialized for client 4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Dataloaders initialized for client 4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Initialized with FedProx Œº = 0.1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Current Round: 10\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Total Rounds: 10\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Using normal mode for scheduling\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Round 10 | Dynamic Stochastic Factor: 0.0000\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Random Sample: 0.9081\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: TaLoS Local Layer Selection (stochastic_factor=0.0000)\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Max Batches: 4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Selected Layers (Min Loss): [6, 10, 1]\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üü¢ Pruning will be applied to the following layers: [6, 10, 1]\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Starting TaLoS calibration in mode: pfededit\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîé Starting multi-round calibration for mode 'pfededit'.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 1/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 2/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 3/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 4/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mask Calibration Completed!\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîç Mapping parameters to their masks...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mapped 36 parameters to masks.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Using SparseAdamW optimizer\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Starting epoch 1/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 1 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 4-LOG: Completed local training - Loss: 4.5428 | Accuracy: 0.0772\n",
            "Aggregating fit results for round 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 11]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 1 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m LOG: Initializing client with CID=3\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Data partition assigned to client 3 -> Non-IID\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Model initialized for client 3\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Dataloaders initialized for client 3\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Initialized with FedProx Œº = 0.1\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Current Round: 11\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Total Rounds: 10\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Using normal mode for scheduling\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Round 11 | Dynamic Stochastic Factor: 0.0000\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Random Sample: 0.3807\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: TaLoS Local Layer Selection (stochastic_factor=0.0000)\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m Max Batches: 4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Selected Layers (Min Loss): [9, 2, 1]\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üü¢ Pruning will be applied to the following layers: [9, 2, 1]\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Starting TaLoS calibration in mode: pfededit\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîé Starting multi-round calibration for mode 'pfededit'.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 1/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 2/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 3/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üåÄ Calibration Round 4/4\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üìù Calculating Fisher Information on 3 batches...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Fisher Information Computation Completed.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mask Calibration Completed!\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m üîç Mapping parameters to their masks...\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m ‚úÖ Mapped 36 parameters to masks.\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Using SparseAdamW optimizer\n",
            "\u001b[36m(ClientAppActor pid=10078)\u001b[0m 3-LOG: Starting epoch 1/1\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flwr/simulation/run_simulation.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(num_supernodes, backend_name, backend_config_stream, app_dir, is_app, enable_tf_gpu_growth, run, exit_event, flwr_dir, client_app, client_app_attr, server_app, server_app_attr, server_app_run_config)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;31m# Start Simulation Engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         vce.start_vce(\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0mnum_supernodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_supernodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\u001b[0m in \u001b[0;36mstart_vce\u001b[0;34m(backend_name, backend_config_json_stream, app_dir, is_app, f_stop, run, flwr_dir, client_app, client_app_attr, num_supernodes, state_factory, existing_nodes_mapping)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;31m# Run main simulation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         run_api(\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0mapp_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\u001b[0m in \u001b[0;36mrun_api\u001b[0;34m(app_fn, backend_fn, nodes_mapping, state_factory, node_info_stores, f_stop)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             _ = [\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0b11303766f6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m run_simulation(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mserver_app\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_app\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mclient_app\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient_app\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_supernodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLIENTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbackend_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flwr/simulation/run_simulation.py\u001b[0m in \u001b[0;36mrun_simulation\u001b[0;34m(server_app, client_app, num_supernodes, backend_name, backend_config, enable_tf_gpu_growth, verbose_logging)\u001b[0m\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     _ = _run_simulation(\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0mnum_supernodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_supernodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mclient_app\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient_app\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flwr/simulation/run_simulation.py\u001b[0m in \u001b[0;36m_run_simulation\u001b[0;34m(num_supernodes, exit_event, client_app, server_app, backend_name, backend_config, client_app_attr, server_app_attr, server_app_run_config, app_dir, flwr_dir, run, enable_tf_gpu_growth, verbose_logging, is_app)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_logger_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mupdated_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdated_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flwr/simulation/run_simulation.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(num_supernodes, backend_name, backend_config_stream, app_dir, is_app, enable_tf_gpu_growth, run, exit_event, flwr_dir, client_app, client_app_attr, server_app, server_app_attr, server_app_run_config)\u001b[0m\n\u001b[1;32m    404\u001b[0m         )\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mserverapp_th\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mserverapp_th\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mserver_app_thread_has_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exception in ServerApp thread\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "run_simulation(\n",
        "    server_app=server_app,\n",
        "    client_app=client_app,\n",
        "    num_supernodes=NUM_CLIENTS,\n",
        "    backend_config=backend_config\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmlarjszyoTm"
      },
      "outputs": [],
      "source": [
        "final_parameters = strategy.latest_parameters\n",
        "\n",
        "# Convert Flower parameters to list of numpy arrays\n",
        "ndarrays = parameters_to_ndarrays(final_parameters)\n",
        "\n",
        "# Load them into a PyTorch model\n",
        "iid_model = create_dino_vit_s16_for_cifar100()\n",
        "iid_model.to(device)\n",
        "state_dict = OrderedDict(\n",
        "    (key, torch.tensor(val)) for key, val in zip(iid_model.state_dict().keys(), ndarrays)\n",
        ")\n",
        "iid_model.load_state_dict(state_dict)\n",
        "\n",
        "correct, total, loss_total = 0, 0, 0.0\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = iid_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss_total += loss.item() * labels.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss = loss_total / total\n",
        "test_accuracy = correct / total\n",
        "\n",
        "logger.log_global_metrics({\n",
        "    \"test_loss\": test_loss,\n",
        "    \"test_accuracy\": test_accuracy\n",
        "}, round_number=NUM_ROUNDS)\n",
        "\n",
        "model_save_path = \"final_federated_model.pth\"\n",
        "torch.save(iid_model.state_dict(), model_save_path)\n",
        "\n",
        "logger.log_model(iid_model, path=model_save_path)\n",
        "\n",
        "logger.finish()\n",
        "\n",
        "print(f\"‚úÖ Test Accuracy: {test_accuracy:.4f} | Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyXTpniJcQAX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
