{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9f8369263e24dd6a9c75985b204b7e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9242270790274736b6bb808966081941",
              "IPY_MODEL_2af55a5a42d142afa45bfcb6c21fb88e",
              "IPY_MODEL_94e51afd8bff4982a77953af6c8d7fb5"
            ],
            "layout": "IPY_MODEL_9cf40ef394b8435cb117182553970aea"
          }
        },
        "9242270790274736b6bb808966081941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6a0f9aa0f2c4954a6e5b351940051b9",
            "placeholder": "​",
            "style": "IPY_MODEL_7de1a9792b7043c7a7def686b5d8c988",
            "value": "model.safetensors: 100%"
          }
        },
        "2af55a5a42d142afa45bfcb6c21fb88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d5d1fc097a3409b9dafef79aa16f00d",
            "max": 86676340,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5a750eadfae48509ad9abe8890eae75",
            "value": 86676340
          }
        },
        "94e51afd8bff4982a77953af6c8d7fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d624039611334d5f9d541ada80e04c2f",
            "placeholder": "​",
            "style": "IPY_MODEL_e025917f7303485182785803e00b36dc",
            "value": " 86.7M/86.7M [00:00&lt;00:00, 187MB/s]"
          }
        },
        "9cf40ef394b8435cb117182553970aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a0f9aa0f2c4954a6e5b351940051b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7de1a9792b7043c7a7def686b5d8c988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d5d1fc097a3409b9dafef79aa16f00d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a750eadfae48509ad9abe8890eae75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d624039611334d5f9d541ada80e04c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e025917f7303485182785803e00b36dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqiZUA23WwuU",
        "outputId": "66bda55e-0aed-428a-9d39-41fc56e103c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.30.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting ray[tune]\n",
            "  Downloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (8.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (24.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (5.29.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (1.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2.2.2)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune])\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pyarrow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (18.1.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2025.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=1.9->ray[tune]) (2.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (0.24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ray[tune]) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->ray[tune]) (4.13.1)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl (68.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX, ray\n",
            "Successfully installed ray-2.44.1 tensorboardX-2.6.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install timm torchvision\n",
        "!pip install ray[tune]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import timm\n",
        "import data_preprocessing\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "LVVEZC-iXZHO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "VAL_SPLIT = 0.1\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SEED = 42"
      ],
      "metadata": {
        "id": "EaFh-l2ZXacd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "torch.manual_seed(SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_CWkSC0XdCU",
        "outputId": "b6e80033-22a1-4455-d14c-a706fe10497b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f884c09c430>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = data_preprocessing.CIFAR100Pipeline(val_split=VAL_SPLIT, use_augment=True)\n",
        "trainset, valset, testset = pipeline.run_pipeline()"
      ],
      "metadata": {
        "id": "PK5ww3zsrHXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9d4b34-cab3-4eab-fc9c-fc6a54086507"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:06<00:00, 26.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valloader = DataLoader(valset, batch_size=BATCH_SIZE)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "7fovaY1kXjUA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "def create_dino_vit_s16_for_cifar100(freezing=True):\n",
        "    model = timm.create_model(\"vit_small_patch16_224_dino\", pretrained=True, num_classes=0)\n",
        "\n",
        "    # Replace the head with CIFAR-100 classification head\n",
        "    model.head = nn.Linear(model.num_features, 100)\n",
        "\n",
        "    if freezing:\n",
        "      # Freeze all parameters except head\n",
        "      for param in model.parameters():\n",
        "          param.requires_grad = False\n",
        "\n",
        "      # Unfreeze only the head\n",
        "      for param in model.head.parameters():\n",
        "          param.requires_grad = True\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_dino_vit_s16_for_cifar100(False).to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "c9f8369263e24dd6a9c75985b204b7e6",
            "9242270790274736b6bb808966081941",
            "2af55a5a42d142afa45bfcb6c21fb88e",
            "94e51afd8bff4982a77953af6c8d7fb5",
            "9cf40ef394b8435cb117182553970aea",
            "f6a0f9aa0f2c4954a6e5b351940051b9",
            "7de1a9792b7043c7a7def686b5d8c988",
            "9d5d1fc097a3409b9dafef79aa16f00d",
            "c5a750eadfae48509ad9abe8890eae75",
            "d624039611334d5f9d541ada80e04c2f",
            "e025917f7303485182785803e00b36dc"
          ]
        },
        "id": "dUJENm4pXjrh",
        "outputId": "af52e7c2-4a52-41b2-d569-fb2d0d0908bc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name vit_small_patch16_224_dino to current vit_small_patch16_224.dino.\n",
            "  model = create_fn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/86.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9f8369263e24dd6a9c75985b204b7e6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(model.parameters()).device)\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Trainable params: {trainable:,} / {total:,}\")\n",
        "\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezKGX0cqjLt1",
        "outputId": "d7660290-9c47-4a78-fb1d-8d888ebe9108"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Trainable params: 21,704,164 / 21,704,164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss, optimizer, scheduler, and scaler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.head.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Early stopping parameters\n",
        "patience = 2\n",
        "best_val_acc = 0.0\n",
        "epochs_no_improve = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    correct, total, train_loss = 0, 0, 0.0\n",
        "\n",
        "    for x, y in trainloader:\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item() * y.size(0)\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    train_acc = correct / total\n",
        "    train_loss /= total\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct, total, val_loss = 0, 0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in valloader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "            val_loss += loss.item() * y.size(0)\n",
        "            _, pred = torch.max(outputs, 1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    val_acc = correct / total\n",
        "    val_loss /= total\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d}/{EPOCHS} — Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # Early stopping logic\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        epochs_no_improve = 0\n",
        "        best_model_state = model.state_dict()  # save best model\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "model.load_state_dict(best_model_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWaOVKGCW7RD",
        "outputId": "a84b9a90-6529-414a-8a21-5d39878513e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-068d4a443b40>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "<ipython-input-40-068d4a443b40>:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01/20 — Train Acc: 0.5744 | Val Acc: 0.6188\n",
            "Epoch 02/20 — Train Acc: 0.6757 | Val Acc: 0.6490\n",
            "Epoch 03/20 — Train Acc: 0.7086 | Val Acc: 0.6684\n",
            "Epoch 04/20 — Train Acc: 0.7326 | Val Acc: 0.6772\n",
            "Epoch 05/20 — Train Acc: 0.7441 | Val Acc: 0.6836\n",
            "Epoch 06/20 — Train Acc: 0.7604 | Val Acc: 0.6832\n",
            "Epoch 07/20 — Train Acc: 0.7741 | Val Acc: 0.6960\n",
            "Epoch 08/20 — Train Acc: 0.7904 | Val Acc: 0.6936\n",
            "Epoch 09/20 — Train Acc: 0.8032 | Val Acc: 0.6988\n",
            "Epoch 10/20 — Train Acc: 0.8192 | Val Acc: 0.7054\n",
            "Epoch 11/20 — Train Acc: 0.8332 | Val Acc: 0.7184\n",
            "Epoch 12/20 — Train Acc: 0.8461 | Val Acc: 0.7222\n",
            "Epoch 13/20 — Train Acc: 0.8620 | Val Acc: 0.7230\n",
            "Epoch 14/20 — Train Acc: 0.8764 | Val Acc: 0.7254\n",
            "Epoch 15/20 — Train Acc: 0.8918 | Val Acc: 0.7286\n",
            "Epoch 16/20 — Train Acc: 0.9058 | Val Acc: 0.7316\n",
            "Epoch 17/20 — Train Acc: 0.9164 | Val Acc: 0.7350\n",
            "Epoch 18/20 — Train Acc: 0.9243 | Val Acc: 0.7300\n",
            "Epoch 19/20 — Train Acc: 0.9308 | Val Acc: 0.7318\n",
            "Early stopping triggered at epoch 19\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  test\n",
        "model.eval()\n",
        "correct, total, test_loss = 0, 0, 0.0\n",
        "with torch.no_grad():\n",
        "    for x, y in testloader:\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        outputs = model(x)\n",
        "        loss = criterion(outputs, y)\n",
        "\n",
        "        test_loss += loss.item() * y.size(0)\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "test_acc = correct / total\n",
        "test_loss /= total\n",
        "\n",
        "print(f\"\\n Final Test Accuracy: {test_acc:.4f} | Test Loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "id": "5ds3URH9Xq6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7188fe9-734b-4248-89ab-6b9e2b743347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Final Test Accuracy: 0.7395 | Test Loss: 1.6905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ray import tune\n",
        "\n",
        "search_space = {\n",
        "    \"lr\": tune.loguniform(1e-5, 1e-2),\n",
        "    \"momentum\": tune.uniform(0.7, 0.99),\n",
        "    \"weight_decay\": tune.loguniform(1e-6, 1e-3),\n",
        "    \"batch_size\": tune.choice([32, 64, 128]),\n",
        "}"
      ],
      "metadata": {
        "id": "oXOwgOto2ThQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "def get_cifar_transform() -> transforms.Compose:\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Resize CIFAR images to 224x224\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],  # ImageNet means\n",
        "            std=[0.229, 0.224, 0.225]    # ImageNet stds\n",
        "        )\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "hLESFm1R2k68"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ray.train import report\n",
        "def train_vit(config):\n",
        "    # Create model\n",
        "    model = create_dino_vit_s16_for_cifar100().to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Optimizer, scheduler, AMP\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=config[\"lr\"],\n",
        "        momentum=config[\"momentum\"],\n",
        "        weight_decay=config[\"weight_decay\"]\n",
        "    )\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    # Load data using your custom pipeline (w/ or w/o augmentation)\n",
        "    pipeline = data_preprocessing.CIFAR100Pipeline(val_split=VAL_SPLIT, use_augment=True)\n",
        "    trainset, valset, testset = pipeline.run_pipeline()\n",
        "\n",
        "    trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "    valloader = DataLoader(valset, batch_size=config[\"batch_size\"])\n",
        "    testloader = DataLoader(testset, batch_size=config[\"batch_size\"])\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    for epoch in range(20):\n",
        "        model.train()\n",
        "        correct, total, train_loss = 0, 0, 0.0\n",
        "\n",
        "        for x, y in trainloader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(x)\n",
        "                loss = criterion(outputs, y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            train_loss += loss.item() * y.size(0)\n",
        "            _, pred = outputs.max(1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "        scheduler.step()\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct, total, val_loss = 0, 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for x, y in valloader:\n",
        "                x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "                outputs = model(x)\n",
        "                loss = criterion(outputs, y)\n",
        "                val_loss += loss.item() * y.size(0)\n",
        "                _, pred = outputs.max(1)\n",
        "                correct += (pred == y).sum().item()\n",
        "                total += y.size(0)\n",
        "\n",
        "        val_acc = correct / total\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "    report({\"val_accuracy\": val_acc, \"train_accuracy\": train_acc})"
      ],
      "metadata": {
        "id": "3uIAmC__2Vvb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.search.basic_variant import BasicVariantGenerator\n",
        "import os\n",
        "\n",
        "results_dir = os.path.abspath(\"ray_results\")\n",
        "storage_uri = f\"file://{results_dir}\"\n",
        "\n",
        "analysis = tune.run(\n",
        "    train_vit,\n",
        "    config=search_space,\n",
        "    storage_path=storage_uri,\n",
        "    search_alg=BasicVariantGenerator(),\n",
        "    num_samples=10,\n",
        "    resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n",
        "    scheduler=ASHAScheduler(metric=\"val_accuracy\", mode=\"max\"),\n",
        "    name=\"vit_hyperparam_search\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xswSeE3O2ZEo",
        "outputId": "cc8bcb0a-62c5-44b0-839e-9a6c53bb27b2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------+\n",
            "| Configuration for experiment     vit_hyperparam_search   |\n",
            "+----------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator   |\n",
            "| Scheduler                        AsyncHyperBandScheduler |\n",
            "| Number of trials                 10                      |\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/ray_results/vit_hyperparam_search\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-04-17_08-25-35_121040_820/artifacts/2025-04-17_08-36-11/vit_hyperparam_search/driver_artifacts`\n",
            "\n",
            "Trial status: 10 PENDING\n",
            "Current time: 2025-04-17 08:36:11. Total running time: 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+---------------------------------------------------------------------------------------------+\n",
            "| Trial name              status              lr     momentum     weight_decay     batch_size |\n",
            "+---------------------------------------------------------------------------------------------+\n",
            "| train_vit_045fe_00000   PENDING    2.5067e-05      0.715299      0.000359066             64 |\n",
            "| train_vit_045fe_00001   PENDING    0.00132097      0.704371      5.66508e-05             32 |\n",
            "| train_vit_045fe_00002   PENDING    1.09955e-05     0.900448      7.24943e-06            128 |\n",
            "| train_vit_045fe_00003   PENDING    5.79904e-05     0.865917      1.18338e-05            128 |\n",
            "| train_vit_045fe_00004   PENDING    0.00585614      0.781448      0.000790279            128 |\n",
            "| train_vit_045fe_00005   PENDING    0.00235607      0.755199      2.31921e-06             64 |\n",
            "| train_vit_045fe_00006   PENDING    0.00013758      0.859437      0.000124581            128 |\n",
            "| train_vit_045fe_00007   PENDING    0.000184583     0.732886      0.000108942            128 |\n",
            "| train_vit_045fe_00008   PENDING    0.000121329     0.827436      6.60215e-06             64 |\n",
            "| train_vit_045fe_00009   PENDING    0.0016574       0.828017      3.35036e-05             32 |\n",
            "+---------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_vit_045fe_00000 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_vit_045fe_00000 config             |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                  64 |\n",
            "| lr                                       3e-05 |\n",
            "| momentum                                0.7153 |\n",
            "| weight_decay                           0.00036 |\n",
            "+------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(train_vit pid=5427)\u001b[0m /usr/local/lib/python3.11/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name vit_small_patch16_224_dino to current vit_small_patch16_224.dino.\n",
            "\u001b[36m(train_vit pid=5427)\u001b[0m   model = create_fn(\n",
            "\u001b[36m(train_vit pid=5427)\u001b[0m <ipython-input-24-1afdde7e2e4f>:15: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  0%|          | 0.00/169M [00:00<?, ?B/s]\n",
            "  0%|          | 65.5k/169M [00:00<08:00, 352kB/s]\n",
            "  0%|          | 229k/169M [00:00<04:15, 660kB/s] \n",
            "  0%|          | 754k/169M [00:00<01:20, 2.08MB/s]\n",
            "  1%|          | 1.41M/169M [00:00<00:48, 3.45MB/s]\n",
            "  2%|▏         | 3.24M/169M [00:00<00:20, 7.98MB/s]\n",
            "  3%|▎         | 5.47M/169M [00:00<00:13, 12.3MB/s]\n",
            "  5%|▌         | 8.68M/169M [00:00<00:08, 18.3MB/s]\n",
            "  7%|▋         | 12.4M/169M [00:00<00:06, 23.8MB/s]\n",
            "  9%|▉         | 15.7M/169M [00:01<00:06, 22.7MB/s]\n",
            " 11%|█▏        | 19.1M/169M [00:01<00:05, 25.8MB/s]\n",
            " 13%|█▎        | 22.6M/169M [00:01<00:05, 28.3MB/s]\n",
            " 15%|█▌        | 26.1M/169M [00:01<00:04, 30.2MB/s]\n",
            " 17%|█▋        | 29.6M/169M [00:01<00:04, 31.4MB/s]\n",
            " 20%|█▉        | 33.1M/169M [00:01<00:04, 31.6MB/s]\n",
            " 22%|██▏       | 36.5M/169M [00:01<00:04, 32.5MB/s]\n",
            " 24%|██▎       | 40.0M/169M [00:01<00:03, 33.0MB/s]\n",
            " 26%|██▌       | 43.5M/169M [00:01<00:03, 33.5MB/s]\n",
            " 28%|██▊       | 47.0M/169M [00:02<00:03, 33.9MB/s]\n",
            " 30%|██▉       | 50.4M/169M [00:02<00:03, 34.1MB/s]\n",
            " 32%|███▏      | 53.8M/169M [00:02<00:03, 29.1MB/s]\n",
            " 34%|███▍      | 57.3M/169M [00:02<00:03, 30.5MB/s]\n",
            " 36%|███▌      | 60.8M/169M [00:02<00:03, 31.6MB/s]\n",
            " 38%|███▊      | 64.2M/169M [00:02<00:03, 32.5MB/s]\n",
            " 40%|████      | 67.7M/169M [00:02<00:03, 33.1MB/s]\n",
            " 42%|████▏     | 71.1M/169M [00:02<00:03, 32.6MB/s]\n",
            " 44%|████▍     | 74.6M/169M [00:02<00:02, 33.2MB/s]\n",
            " 46%|████▌     | 78.0M/169M [00:03<00:02, 33.3MB/s]\n",
            " 48%|████▊     | 81.4M/169M [00:03<00:02, 33.6MB/s]\n",
            " 50%|█████     | 84.9M/169M [00:03<00:02, 33.9MB/s]\n",
            " 52%|█████▏    | 88.4M/169M [00:03<00:02, 34.2MB/s]\n",
            " 54%|█████▍    | 91.8M/169M [00:03<00:02, 29.3MB/s]\n",
            " 56%|█████▋    | 95.3M/169M [00:03<00:02, 30.7MB/s]\n",
            " 58%|█████▊    | 98.8M/169M [00:03<00:02, 31.8MB/s]\n",
            " 61%|██████    | 102M/169M [00:03<00:02, 32.7MB/s] \n",
            " 62%|██████▏   | 106M/169M [00:03<00:01, 32.8MB/s]\n",
            " 65%|██████▍   | 109M/169M [00:03<00:01, 33.7MB/s]\n",
            " 67%|██████▋   | 113M/169M [00:04<00:01, 32.9MB/s]\n",
            " 69%|██████▊   | 116M/169M [00:04<00:01, 33.4MB/s]\n",
            " 71%|███████   | 120M/169M [00:04<00:01, 33.8MB/s]\n",
            " 73%|███████▎  | 123M/169M [00:04<00:01, 33.9MB/s]\n",
            " 75%|███████▍  | 127M/169M [00:04<00:01, 34.3MB/s]\n",
            " 77%|███████▋  | 130M/169M [00:04<00:01, 29.2MB/s]\n",
            " 79%|███████▉  | 133M/169M [00:04<00:01, 30.6MB/s]\n",
            " 81%|████████  | 137M/169M [00:04<00:01, 31.7MB/s]\n",
            " 83%|████████▎ | 140M/169M [00:04<00:00, 32.6MB/s]\n",
            " 85%|████████▌ | 144M/169M [00:05<00:00, 33.0MB/s]\n",
            " 87%|████████▋ | 147M/169M [00:05<00:00, 32.5MB/s]\n",
            " 89%|████████▉ | 151M/169M [00:05<00:00, 33.2MB/s]\n",
            " 91%|█████████▏| 154M/169M [00:05<00:00, 33.6MB/s]\n",
            " 93%|█████████▎| 158M/169M [00:05<00:00, 33.5MB/s]\n",
            " 95%|█████████▌| 161M/169M [00:05<00:00, 34.4MB/s]\n",
            " 98%|█████████▊| 165M/169M [00:05<00:00, 29.7MB/s]\n",
            "100%|█████████▉| 168M/169M [00:05<00:00, 30.8MB/s]\n",
            "100%|██████████| 169M/169M [00:05<00:00, 29.0MB/s]\n",
            "\u001b[36m(train_vit pid=5427)\u001b[0m <ipython-input-24-1afdde7e2e4f>:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2025-04-17 08:36:41. Total running time: 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+---------------------------------------------------------------------------------------------+\n",
            "| Trial name              status              lr     momentum     weight_decay     batch_size |\n",
            "+---------------------------------------------------------------------------------------------+\n",
            "| train_vit_045fe_00000   RUNNING    2.5067e-05      0.715299      0.000359066             64 |\n",
            "| train_vit_045fe_00001   PENDING    0.00132097      0.704371      5.66508e-05             32 |\n",
            "| train_vit_045fe_00002   PENDING    1.09955e-05     0.900448      7.24943e-06            128 |\n",
            "| train_vit_045fe_00003   PENDING    5.79904e-05     0.865917      1.18338e-05            128 |\n",
            "| train_vit_045fe_00004   PENDING    0.00585614      0.781448      0.000790279            128 |\n",
            "| train_vit_045fe_00005   PENDING    0.00235607      0.755199      2.31921e-06             64 |\n",
            "| train_vit_045fe_00006   PENDING    0.00013758      0.859437      0.000124581            128 |\n",
            "| train_vit_045fe_00007   PENDING    0.000184583     0.732886      0.000108942            128 |\n",
            "| train_vit_045fe_00008   PENDING    0.000121329     0.827436      6.60215e-06             64 |\n",
            "| train_vit_045fe_00009   PENDING    0.0016574       0.828017      3.35036e-05             32 |\n",
            "+---------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2025-04-17 08:37:12. Total running time: 1min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+---------------------------------------------------------------------------------------------+\n",
            "| Trial name              status              lr     momentum     weight_decay     batch_size |\n",
            "+---------------------------------------------------------------------------------------------+\n",
            "| train_vit_045fe_00000   RUNNING    2.5067e-05      0.715299      0.000359066             64 |\n",
            "| train_vit_045fe_00001   PENDING    0.00132097      0.704371      5.66508e-05             32 |\n",
            "| train_vit_045fe_00002   PENDING    1.09955e-05     0.900448      7.24943e-06            128 |\n",
            "| train_vit_045fe_00003   PENDING    5.79904e-05     0.865917      1.18338e-05            128 |\n",
            "| train_vit_045fe_00004   PENDING    0.00585614      0.781448      0.000790279            128 |\n",
            "| train_vit_045fe_00005   PENDING    0.00235607      0.755199      2.31921e-06             64 |\n",
            "| train_vit_045fe_00006   PENDING    0.00013758      0.859437      0.000124581            128 |\n",
            "| train_vit_045fe_00007   PENDING    0.000184583     0.732886      0.000108942            128 |\n",
            "| train_vit_045fe_00008   PENDING    0.000121329     0.827436      6.60215e-06             64 |\n",
            "| train_vit_045fe_00009   PENDING    0.0016574       0.828017      3.35036e-05             32 |\n",
            "+---------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-17 08:37:17,720\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
            "2025-04-17 08:37:17,727\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/ray_results/vit_hyperparam_search' in 0.0062s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2025-04-17 08:37:17. Total running time: 1min 5s\n",
            "Logical resource usage: 2.0/2 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+---------------------------------------------------------------------------------------------+\n",
            "| Trial name              status              lr     momentum     weight_decay     batch_size |\n",
            "+---------------------------------------------------------------------------------------------+\n",
            "| train_vit_045fe_00000   RUNNING    2.5067e-05      0.715299      0.000359066             64 |\n",
            "| train_vit_045fe_00001   PENDING    0.00132097      0.704371      5.66508e-05             32 |\n",
            "| train_vit_045fe_00002   PENDING    1.09955e-05     0.900448      7.24943e-06            128 |\n",
            "| train_vit_045fe_00003   PENDING    5.79904e-05     0.865917      1.18338e-05            128 |\n",
            "| train_vit_045fe_00004   PENDING    0.00585614      0.781448      0.000790279            128 |\n",
            "| train_vit_045fe_00005   PENDING    0.00235607      0.755199      2.31921e-06             64 |\n",
            "| train_vit_045fe_00006   PENDING    0.00013758      0.859437      0.000124581            128 |\n",
            "| train_vit_045fe_00007   PENDING    0.000184583     0.732886      0.000108942            128 |\n",
            "| train_vit_045fe_00008   PENDING    0.000121329     0.827436      6.60215e-06             64 |\n",
            "| train_vit_045fe_00009   PENDING    0.0016574       0.828017      3.35036e-05             32 |\n",
            "+---------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4f6350c146c2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstorage_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"file://{results_dir}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m analysis = tune.run(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_vit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mall_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0mincomplete_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ray/tune/execution/tune_controller.py\u001b[0m in \u001b[0;36mcleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1973\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[0;34m\"\"\"Cleanup trials and callbacks.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1975\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cleanup_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1976\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_experiment_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ray/tune/execution/tune_controller.py\u001b[0m in \u001b[0;36m_cleanup_trials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    801\u001b[0m                     \u001b[0;34m\"Waiting for actor manager to clean up final state [dedup]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                 )\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actor_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Force cleanup of remaining actors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ray/air/execution/_internal/actor_manager.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mstart_wait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_futures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_returns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\u001b[0m in \u001b[0;36mauto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mauto_init_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mauto_init_ray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mauto_init_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   3011\u001b[0m         \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3012\u001b[0m         \u001b[0mtimeout_milliseconds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3013\u001b[0;31m         ready_ids, remaining_ids = worker.core_worker.wait(\n\u001b[0m\u001b[1;32m   3014\u001b[0m             \u001b[0mray_waitables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3015\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpython/ray/includes/common.pxi\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8QVlnlG5CLS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}